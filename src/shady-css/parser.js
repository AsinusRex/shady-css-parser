import { Tokenizer } from './tokenizer';
import { Token } from './token';
import { NodeFactory } from './node-factory';

/**
 * Class that implements a CSS parser.
 */
class Parser {
  /**
   * Create a Parser instance. When creating a Parser instance, a specialized
   * NodeFactory can be supplied to implement streaming analysis and
   * manipulation of the CSS AST.
   */
  constructor(nodeFactory = new NodeFactory()) {
    this.nodeFactory = nodeFactory;
  }

  /**
   * Parse CSS and generate an AST.
   * @param {string} cssText The CSS to parse.
   * @return {object} A CSS AST containing nodes that correspond to those
   * generated by the Parser's NodeFactory.
   */
  parse(cssText) {
    return this.parseStylesheet(new Tokenizer(cssText));
  }

  /**
   * Consumes tokens from a Tokenizer to parse a Stylesheet node.
   * @param {Tokenizer} tokenizer A Tokenizer instance.
   * @return {object} A Stylesheet node.
   */
  parseStylesheet(tokenizer) {
    return this.nodeFactory.stylesheet(this.parseRules(tokenizer));
  }

  /**
   * Consumes tokens from a Tokenizer to parse rules.
   * @param {Tokenizer} tokenizer A Tokenizer instance.
   * @return {array} A list of nodes corresponding to rules. Any of Comment,
   * AtRule, Selector, Declaration and Discarded nodes may be present in the
   * list.
   */
  parseRules(tokenizer) {
    let rules = [];

    while (tokenizer.currentToken) {
      let rule = this.parseRule(tokenizer);

      if (rule) {
        rules.push(rule);
      }
    }

    return rules;
  }

  parseRule(tokenizer) {
    // Trim leading whitespace:
    if (tokenizer.currentToken.is(Token.type.whitespace)) {
      tokenizer.advance();
      return null;
    } else if (tokenizer.currentToken.is(Token.type.comment)) {
      return this.parseComment(tokenizer)

    } else if (tokenizer.currentToken.is(Token.type.propertyBoundary)) {
      return this.parseUnknown(tokenizer);

    } else if (tokenizer.currentToken.is(Token.type.word)) {
      return this.parseDeclarationOrSelector(tokenizer);

    } else if (tokenizer.currentToken.is(Token.type.at)) {
      return this.parseAtRule(tokenizer);

    } else {
      return this.parseUnknown(tokenizer);
    }
  }

  /**
   * Consumes tokens from a Tokenizer to parse a Comment node.
   * @param {Tokenizer} tokenizer A Tokenizer instance.
   * @return {object} A Comment node.
   */
  parseComment(tokenizer) {
    return this.nodeFactory.comment(tokenizer.slice(tokenizer.advance()));
  }

  /**
   * Consumes tokens from a Tokenizer through the next boundary token to
   * produce a Discarded node. This supports graceful recovery from many
   * malformed CSS conditions.
   * @param {Tokenizer} tokenizer A Tokenizer instance.
   * @return {object} A Discarded node.
   */
  parseUnknown(tokenizer) {
    let start = tokenizer.advance();
    let end;

    while (tokenizer.currentToken) {
      if (tokenizer.currentToken.is(Token.type.boundary) &&
          !tokenizer.currentToken.is(Token.type.semicolon)) {
        break;
      }

      end = tokenizer.advance();
    }

    return this.nodeFactory.discarded(tokenizer.slice(start, end));
  }

  /**
   * Consumes tokens from a Tokenizer to parse an At Rule node.
   * @param {Tokenizer} tokenizer A Tokenizer instance.
   * @return {object} An At Rule node.
   */
  parseAtRule(tokenizer) {
    let name = '';
    let ruleset = null;
    let parametersStart = null;
    let parametersEnd = null;

    while (tokenizer.currentToken) {
      if (tokenizer.currentToken.is(Token.type.whitespace)) {
        tokenizer.advance();
      } else if (!name && tokenizer.currentToken.is(Token.type.at)) {
        // Discard the @:
        tokenizer.advance();
        let start = tokenizer.currentToken;
        let end;

        while (tokenizer.currentToken &&
               tokenizer.currentToken.is(Token.type.word)) {
          end = tokenizer.advance();
        }
        name = tokenizer.slice(start, end);
      } else if (tokenizer.currentToken.is(Token.type.openBrace)) {
        ruleset = this.parseRuleset(tokenizer);
        break;
      } else if (tokenizer.currentToken.is(Token.type.propertyBoundary)) {
        tokenizer.advance();
        break;
      } else {
        if (parametersStart == null) {
          parametersStart = tokenizer.advance();
        } else {
          parametersEnd = tokenizer.advance();
        }
      }
    }

    return this.nodeFactory.atRule(
        name,
        parametersStart ? tokenizer.slice(parametersStart, parametersEnd) : '',
        ruleset);
  }

  /**
   * Consumes tokens from a Tokenizer to produce a Block node.
   * @param {Tokenizer} tokenizer A Tokenizer instance.
   * @return {object} A Block node.
   */
  parseRuleset(tokenizer) {
    let rules = [];

    // Take the opening { boundary:
    tokenizer.advance();

    while (tokenizer.currentToken) {
      if (tokenizer.currentToken.is(Token.type.closeBrace)) {
        tokenizer.advance();
        break;
      } else {
        let rule = this.parseRule(tokenizer);
        if (rule) {
          rules.push(rule);
        }
      }
    }

    return this.nodeFactory.ruleset(rules);
  }

  /**
   * Consumes tokens from a Tokenizer instance to produce a Property node or
   * a Selector node, as appropriate.
   * @param {Tokenizer} tokenizer A Tokenizer node.
   * @return {object} One of a Property or Selector node.
   */
  parseDeclarationOrSelector(tokenizer) {
    let rule = '';
    let ruleStart = null;
    let ruleEnd = null;

    while (tokenizer.currentToken) {
      if (tokenizer.currentToken.is(Token.type.whitespace)) {
        tokenizer.advance();
      } else if (tokenizer.currentToken.is(Token.type.openParenthesis)) {
        while (tokenizer.currentToken &&
               !tokenizer.currentToken.is(Token.type.closeParenthesis)) {
          tokenizer.advance();
        }
      } else if (tokenizer.currentToken.is(Token.type.openBrace) ||
                 tokenizer.currentToken.is(Token.type.propertyBoundary)) {
        break;
      } else {
        if (!ruleStart) {
          ruleStart = tokenizer.advance();
        } else {
          ruleEnd = tokenizer.advance();
        }
      }
    }

    rule = tokenizer.slice(ruleStart, ruleEnd);

    // A selector never contains or ends with a semi-colon.
    if (tokenizer.currentToken.is(Token.type.propertyBoundary)) {
      let colonIndex = rule.indexOf(':');
      // TODO(cdata): is .trim() bad for performance?
      let value = rule.substr(colonIndex + 1).trim();

      if (tokenizer.currentToken.is(Token.type.semicolon)) {
        tokenizer.advance();
      }

      return this.nodeFactory.declaration(
          rule.substr(0, colonIndex),
          this.nodeFactory.expression(value));
    } else if (rule[rule.length - 1] === ':') {
      let ruleset = this.parseRuleset(tokenizer);

      if (tokenizer.currentToken.is(Token.type.semicolon)) {
        tokenizer.advance();
      }

      return this.nodeFactory.declaration(
          rule.substr(0, rule.length - 1), ruleset);
    } else {
      return this.nodeFactory.selector(rule.trim(), this.parseRuleset(tokenizer));
    }
  }
}

export { Parser };
